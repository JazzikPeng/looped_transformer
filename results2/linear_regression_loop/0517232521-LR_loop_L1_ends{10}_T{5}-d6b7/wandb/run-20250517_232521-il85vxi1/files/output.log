WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0
number of parameters: 0.79M
train from scratch
  0%|                                                                                                                                                                                                                                  | 0/500000 [00:00<?, ?it/s]



